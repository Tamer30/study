Создание блоков
Блоки для кросс-валидации создают несколько методов в sklearn. Один из них реализован в классе KFold модуля sklearn.model_selection:

from sklearn.model_selection import KFold

# датасет
X = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

kfold = KFold(n_splits=5) 

Настройка n_splits задаёт количество блоков, на которые будут разделены данные. 
Основной метод KFold — split(). Он возвращает объект-генератор, который разбивает данные на блоки и позволяет выводить индексы объектов, которые попали в тренировочную и валидационную выборки на каждом этапе кросс-валидации. 

print(type(kfold.split(X))) 

<class 'generator'> 

Во время кросс-валидации модель обучается один раз.
Кросс-валидация точнее оценивает качество модели. Она компенсирует разделение данных случайным образом и обобщает метрики.
Сравните: без кросс-валидации вы проверяете модель только на 25% данных, все остальные в тренировочной выборке. Это может занизить или завысить метрики: вы не знаете, как train_test_split() распределит данные. При перекрёстной проверке такой проблемы нет: каждый из блоков окажется валидационным на одном из этапов, и так вы проверите модель на 100% данных.
Единственный недостаток кросс-валидации — она требует времени на вычисления при большом количестве наблюдений или блоков.
Создание блоков
Блоки для кросс-валидации создают несколько методов в sklearn. Один из них реализован в классе KFold модуля sklearn.model_selection:

from sklearn.model_selection import KFold

# датасет
X = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

kfold = KFold(n_splits=5) 

Настройка n_splits задаёт количество блоков, на которые будут разделены данные. 
Основной метод KFold — split(). Он возвращает объект-генератор, который разбивает данные на блоки и позволяет выводить индексы объектов, которые попали в тренировочную и валидационную выборки на каждом этапе кросс-валидации. 

print(type(kfold.split(X))) 

<class 'generator'> 

Чтобы увидеть распределение объектов по их индексам после того, как split() поделит исходные данные, используйте цикл for ... in для каждой из полученных выборок:

from sklearn.model_selection import KFold

# загрузка данных из CSV-файла в датафрейм pandas
X = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

kfold = KFold(n_splits=5)

for train_split, test_split in kfold.split(X):
    print(f"Тренировочные: {X[train_split]}, Валидационные: {X[test_split]}") 

Тренировочные: [2 3 4 5 6 7 8 9], Валидационные: [0 1]
Тренировочные: [0 1 4 5 6 7 8 9], Валидационные: [2 3]
Тренировочные: [0 1 2 3 6 7 8 9], Валидационные: [4 5]
Тренировочные: [0 1 2 3 4 5 8 9], Валидационные: [6 7]
Тренировочные: [0 1 2 3 4 5 6 7], Валидационные: [8 9] 

Каждое наблюдение побывало в роли валидационного. В результате модель пройдёт проверку на всех данных, и оценка её качества будет более объективна.
У класса KFold есть параметр shuffle, его значение по умолчанию False. Если изменить его на True, то данные перед разбиением на блоки будут перемешаны. Из-за этого в тренировочной выборке объекты могут несколько раз оказаться в одном и том же блоке. Валидационные данные не будут совпадать, если в данных нет дубликатов.

from sklearn.model_selection import KFold

# загрузка данных из CSV-файла в датафрейм pandas
X = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

kfold = KFold(n_splits=5, shuffle=True, random_state=42)

for train_split, test_split in kfold.split(X):
    print(f"Тренировочные: {X[train_split]}, Валидационные: {X[test_split]}") 

Тренировочные: [0 2 3 4 5 6 7 9], Валидационные: [1 8]
Тренировочные: [1 2 3 4 6 7 8 9], Валидационные: [0 5]
Тренировочные: [0 1 3 4 5 6 8 9], Валидационные: [2 7]
Тренировочные: [0 1 2 3 5 6 7 8], Валидационные: [4 9]
Тренировочные: [0 1 2 4 5 7 8 9], Валидационные: [3 6] 

Не забывайте — метод возвращает не сами объекты, а их индексы!
В отличие от предыдущего примера, валидационные данные идут не по порядку. Это говорит о том, что перед разбиением на блоки датасет перемешался.

Поэтому для несбалансированных данных создан отдельный метод — StratifiedKFold. Он работает так же, как и у KFold, но при его использовании методу split() нужно передать целевой признак y. Тогда генератор учтёт распределение по классам при формировании блоков данных. 

s_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
s_kfold.split(X, y) 



####################################################################

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.metrics import f1_score

# Создание константы RANDOM_STATE
RANDOM_STATE = 42

# Загрузка данных из CSV-файла в датафрейм pandas
df = pd.read_csv('music_genre_2_classes_imbalanced_v2.csv')
X = df.drop(columns='music_genre')
y = df.music_genre

# Формирование тренировочной и тестовой выборок со стратификацией
# Подготовка данных выполнена функцией, все операции в скрытом прекоде
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y)

# Подготовка данных выполнена функцией, все операции в скрытом прекоде
X_train, X_test = prepare_data(X_train, X_test)

# Создание экземпляра StratifiedKFold с пятью блоками
# Используйте перемешивание данных и зафиксируйте random_state
s_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)

# Список для сохранения оценок F1
f1 = []

# Обучение и проверка модели с использованием кросс-валидации
for train_index, test_index in s_kfold.split(X_train, y_train):
    # Разделение данных на тренировочную и валидационную выборки
    X_train_cv, X_test_cv = X_train.iloc[train_index], X_train.iloc[test_index]
    y_train_cv, y_test_cv = y_train.iloc[train_index], y_train.iloc[test_index]
    
    # Инициализация и обучение модели на кросс-валидационной выборке
    model = KNeighborsClassifier()
    model.fit(X_train_cv, y_train_cv)
    
    # Оценка качества модели во время кросс-валидации
    y_pred = model.predict(X_test_cv)
    f1_metric = f1_score(y_test_cv, y_pred, pos_label='Rock')
    
    # Сохранение оценок F1
    f1.append(f1_metric)

# Обучение модели на всех тренировочных данных
model.fit(X_train, y_train)

# Оценка качества модели на тестовой выборке
y_pred_test = model.predict(X_test)
f1_test = f1_score(y_test, y_pred_test, pos_label='Rock')

# Усреднение оценок качества после кросс-валидации
mean_f1 = sum(f1) / len(f1)

# Вывод результатов
print(f"[Кросс-валидация] Все значения F1-score: {[round(x,2) for x in f1]}")
print(f"[Кросс-валидация] Среднее значение F1-score: {mean_f1:.2f}")
print(f"[Тестовая выборка] F1-score: {f1_test:.2f}")

